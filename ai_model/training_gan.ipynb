{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d31187-c4e1-4ce6-a082-8ed3f534fb59",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "This section imports all necessary libraries that are essential for building and training the GAN and processing the data. It includes PyTorch for deep learning tasks, NumPy for handling numerical operations, and OS for file and directory operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5e9a4-5ce3-4545-8ef1-b753c2df7f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b5c9e5-c292-499d-9f3d-49ec0e8ecabe",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data\n",
    "This section defines the `load_data` function which loads and preprocesses the IMU data from specified directories for each type of figure skating jump. It applies necessary scaling to accelerometer and gyroscopic data, preparing it for use in both the GAN and the LSTM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58ab81-a817-4423-ad9f-d11293d1f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    data = []\n",
    "    labels = []\n",
    "    categories = ['axel', 'flip', 'loop', 'lutz', 'salchow', 'toe']\n",
    "    for idx, category in enumerate(categories):\n",
    "        path = os.path.join(directory, category)\n",
    "        for file in os.listdir(path):\n",
    "            file_path = os.path.join(path, file)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                # Load raw data without reshaping\n",
    "                raw_data = np.fromfile(f, dtype=np.int16)\n",
    "                raw_data = raw_data.astype(np.float64)\n",
    "\n",
    "                for i in range(0, len(raw_data), 6):  # Step over each group of 6 (3 accel, 3 gyro)\n",
    "                    # Apply scaling for accelerometer data (indices 0, 1, 2 in each group of 6)\n",
    "                    raw_data[i:i+3] /= 2048.0\n",
    "                    # Apply scaling for gyroscopic data (indices 3, 4, 5 in each group of 6)\n",
    "                    raw_data[i+3:i+6] /= 16.4\n",
    "                \n",
    "                data.append(raw_data)  # Append the scaled flat data\n",
    "                labels.append(idx)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "data, labels = load_data('../data/labeled_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2294360f-8344-41b8-8011-2795371280f4",
   "metadata": {},
   "source": [
    "## Define Directory Paths\n",
    "Set up the paths for the processed data and the directory where the generated data will be stored. Ensure that directories for storing generated data are created if they do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712e96c-c962-4a1a-a844-125d3ed57b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_types = ['axel', 'flip', 'loop', 'lutz', 'salchow', 'toe']\n",
    "base_dir = '../data'\n",
    "processed_data_dir = os.path.join(base_dir, 'processed_data')\n",
    "generated_data_dir = os.path.join(base_dir, 'generated_data')\n",
    "\n",
    "for jump_type in jump_types:\n",
    "    dir_path = os.path.join(generated_data_dir, jump_type)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77704c-3066-4969-b5a0-3ef271494b47",
   "metadata": {},
   "source": [
    "## Generator and Discriminator Architecture\n",
    "Define the structures for the generator and discriminator networks. The generator aims to produce new, synthetic IMU data mimicking real jump data, while the discriminator tries to distinguish between real and generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f2d6d-f5e1-4935-9339-3f1ec268feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator definition\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):  # output_dim set to 4500\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, output_dim),  # Final output matching the discriminator's input size\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# Discriminator definition\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(4500, 1024),  # First input layer accepts a vector of size 4500\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, imu_data):\n",
    "        return self.model(imu_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde0ccd-beec-4071-895c-5cbbe25478fd",
   "metadata": {},
   "source": [
    "## Setup DataLoader\n",
    "Create a DataLoader for the loaded data. This DataLoader will be used to feed data to both the discriminator for real data samples and the GAN for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996df8f2-995d-4ac2-b64a-97d5c438ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_data = torch.Tensor(data)\n",
    "tensor_labels = torch.LongTensor(labels)\n",
    "\n",
    "dataset = TensorDataset(tensor_data, tensor_labels)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b447b5-58ae-4bbd-9a01-5b28f76e07ae",
   "metadata": {},
   "source": [
    "## GAN Training Setup\n",
    "Prepare the environment for training the GAN, including the initialization of the generator and discriminator, defining the loss function, and setting up the optimizers. This setup is crucial for effectively training the GAN to generate realistic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618fbd2-75cc-49c9-b689-a4d0087d90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_dim=100, output_dim=4500)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7600fc6-3913-4832-86e9-dd194161a7a1",
   "metadata": {},
   "source": [
    "## GAN Training Loop\n",
    "Define the training loop for the GAN, where the generator and discriminator are trained alternately. The generator tries to create data that the discriminator will classify as real, while the discriminator learns to distinguish between real and generated data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db0c62-294f-4aff-adb8-548ee35857c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "latent_dim = 100\n",
    "\n",
    "# Define the device as the first visible cuda device if GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_data, _) in enumerate(data_loader):\n",
    "        # Ensure real_data is in the correct shape (batch_size, 4500)\n",
    "        real_data = real_data.view(-1, 4500)  # Reshape real data to match discriminator input\n",
    "\n",
    "        # Generate fake data\n",
    "        z = torch.randn(real_data.size(0), 100)  # Latent space input for generator\n",
    "        generated_data = generator(z)\n",
    "        generated_data = generated_data.view(-1, 4500)  # Ensure generated data is correctly reshaped\n",
    "\n",
    "        # Define targets for real and fake data\n",
    "        valid = torch.ones(real_data.size(0), 1, device=device)\n",
    "        fake = torch.zeros(real_data.size(0), 1, device=device)\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss = adversarial_loss(discriminator(generated_data), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(real_data), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_data.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Discriminator Loss: {d_loss.item()}, Generator Loss: {g_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ef09d-3ce7-4b32-87de-28ebec4e6b86",
   "metadata": {},
   "source": [
    "## GAN Training and Data Generation\n",
    "Modify the GAN training loop to handle different types of jumps. Generate data for each jump type and save it into specific folders structured by jump type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b178b7f-74bf-48ec-bc46-fff1e9fcb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_to_generate = 50\n",
    "\n",
    "generator.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for jump_type in jump_types:\n",
    "        z = torch.randn(num_samples_to_generate, 100, device=device)\n",
    "        generated_data = generator(z)\n",
    "        generated_data = generated_data.view(num_samples_to_generate, -1)  # Ensuring it's flat if not already\n",
    "\n",
    "        # Reverse scaling for accelerometer and gyroscope data\n",
    "        for i in range(0, generated_data.shape[1], 6):  # Assuming the data is structured in groups of 6 as before\n",
    "            generated_data[:, i:i+3] *= 2048.0  # Accelerometer indices\n",
    "            generated_data[:, i+3:i+6] *= 16.4  # Gyroscope indices\n",
    "\n",
    "        # Convert to numpy and adjust datatype to int16\n",
    "        generated_data = generated_data.cpu().numpy().astype(np.int16)\n",
    "\n",
    "        # Save data\n",
    "        for i, data in enumerate(generated_data):\n",
    "            file_path = os.path.join(generated_data_dir, jump_type, f'jump_{i}.bin')\n",
    "            data.tofile(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
